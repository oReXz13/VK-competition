Распознавание ботов
Контекст
Представьте, что у вас есть сервис, который поддерживает регистрацию новых пользователей. Вам стало известно, что вместо реальных пользователей на вашем сайте создается множество бот-акканутов. Боты – это пользователи, которые созданы при помощи автоматических скриптов. Обычно аккаунты, зарегистрированные одним автоскриптом, при незначительных вариациях очень схожи. Мало того, что на ботов тратятся вычислительные ресурсы, так они еще зашумляют бизнес-метрики. Жить так больше нельзя! Поэтому решено построить ML-систему, которая для каждой регистрации ставит в соответствие вероятность: насколько этот пользователь "похож на бота".

Описанная ситуация – это реальная задача Антиспама Почты, и в данном соревновании вам необходимо ее решить. Но есть нюанс: в процессе вам нужно обучить TLS-эмбеддинг!
 
Что такое эмбеддинг?
Эмбеддинг – это векторное представление нечисловых слабоструктурированных данных в некотором многомерном пространстве. Важным свойством такого многомерного пространства является то, что если два исходных объекта похожи, то их эмбеддинги должны быть "близки" в этом пространстве. Наиболее известными примерами являются текстовые эмбеддинги, но эмбеддинги можно обучать для абсолютно разных данных, в том числе для TLS-шифров.
 
А почему TLS-эмбеддинг?
Чтобы “общаться” с использованием TLS, клиент и сервер должны договорится о том, как обмениваться ключами и какими алгоритмами шифровать трафик. Список доступных клиенту алгоритмов определяется платформой, операционной системой, браузером, поэтому боты, которых регистрирует один и тот же автоскрипт, обычно разделяют похожие наборы шифров. Это первая причина.

Вторая причина заключается в следующем: чтобы понять, с какого устройства происходит регистрация, мы используем информацию из HTTP-заголовка User-Agent. Но этот способ не является надежным, так как клиент может вставить абсолютно произвольную строку в данный HTTP-заголовок и это не возможно достоверно выявить. С другой стороны, TLS-шифры, которые предоставляет клиент для сервера, труднее подделать, так как это требует намного более сложных манипуляций на уровне ОС и SSL/TLS-библиотек. Дополнительным аргументом в копилку TLS-шифров будет исследование, в котором по TLS-фингерпринтам достаточно успешно удается определить семейство браузеров.

Поэтому и встает вопрос об обучении векторного представления – эмбеддинга, который описывает поддерживаемые клиентом TLS-шифры. 

Задача
Основная задача соревнования – это бинарная классификация на два класса "Бот" (метка 1) и "Не Бот" (метка 0), используя следующие данные:
юзер-агент клиента;
названия TLS-шифров, которые поддерживает клиент;
названия TLS эллиптических кривых, которые поддерживаются TLS-шифрами клиента.
Данные из пункта 2 и 3 получены в ходе установки TLS-соединения из сообщения ClientHello.
 
Обязательное условие
Мы ожидаем, что для обучения финального классификатора командами будет построен TLS-эмбеддинг, который обучен на TLS-шифрах и TLS-кривых. Командам потребуется загрузить не только предсказания своей модели, но также и код/ноутбук, который генерирует решение для того, чтобы мы могли убедится, что в процессе обучения downstream-классификатора действительно используется предварительно обученный TLS-эмбеддинг. TLS-эмбеддинг может быть обучен
совместно на шифрах и кривых:
 F(Сiphers, Curves) = TLS-embedding;
отдельно на шифрах и отдельно на кривых, а финальный TLS-эмбеддинг получен их конкатенацией:
Concat(F1(Ciphers), F2(Curves)) = TLS-embedding.
Использование данных о юзер-агенте клиента в итоговой классификации не является обязательным, но скорее всего позволит получить более высокое место в лидерборде. На то, как команды будут использовать строку юзер-агента, требований не накладывается, но мы по своему опыту рекомендуем обучить отдельный эмбеддинг (UA-эмбеддинг): 
G(User-Agent) = UA-embedding.
В таком случае финальный классификатор ботов – f – будет выглядит следующим образом:

Pbot = f(UA-embedding, TLS-embedding).
Оценка
Результаты подводятся на private-лидерборде, который открывается по завершении соревнования. Метрика оценки классификации ботов – площадь под ROC-кривой – ROCAUC. У топ-3 команд из private-лидерборда проверяется код на предмет обучения TLS-эмбеддинга. При обнаружении отсутствия построения TLS-эмбеддинга, мы исключаем данное решение и берем следующее по топу.
 
Данные
Данные для обучения представлены в формате Apache Parquet – это бинарный колоночный формат данных, который позволяет хранить данные более оптимально, чем CSV. Для загрузки этих файлов можно использовать привычный Pandas, но потребуется установить либо fastparquet, либо PyArrow.

$ pip install pandas fastparquet
Далее read_csv() заменяется на read_parquet(), и можно работать привычным образом:

import pandas as pd

df = pd.read_parquet("train.parquet")
Командам доступны 3 файла с данными:

train.parquet – размеченные данные для обучения;
test.parquet – неразмеченные данные: для каждого объекта из этой выборки необходимо оценить "вероятность бота";
unlabelled.snappy.parquet – большая неразмеченная выборка: эти данные команды могут использовать опционально для обучения TLS и UA эмбеддингов.
В виду ограничения платформы на размер файла, выборку unlabelled.snappy.parquet можно скачать из облака по ссылке.
 

Важные факты о данных
Для того чтобы сделать задачу более интересной, данные были выбраны с некоторыми нюансами. Основной нюанс касается временного промежутка, за который данные были собраны. 
train.parquet в основном составляют данные за 2021 год;
test.parquet собран в большей мере за 2022 год;
unlabelled.snappy.parquet – это большой неразмеченный сэмпл данных за 2022 год.
Есть второй нюанс, который следует иметь в виду. В выборках присутствуют объекты с трех платформ Почты: Web, iOS, Android. К какой платформе относится объект можно понять по юзер-агенту.
Подсказка
Скорее всего, если вы будете использовать неразмеченный сэмпл для обучения эмбеддингов, то получите более высокое место в лидерборде. 
 
Как обучить эмбеддинги?
Раскрывать все возможные варианты не будем, так как именно здесь команды могут проявить все свое творчество и креативность. Дадим лишь общие направления для исследования.
TLS-эмбеддинг можно обучать как supervised (классификация ботов), так и в unsupervised (self-supservised) режиме, а можно комбинировать оба подхода вместе.
Особо искушенные могут попробовать методы semi-supervised обучения.
Для unsupervised/self-supervised обучения рекомендуем использовать большую неразмеченную выборку.
Для self-supervised обучения советуем присмотреться к таким задачам, как Masked Langauge Modeling (MLM) и др.
Вы можете разделить между участниками команды задачу обучения TLS/UA-эмбеддингов и задачу обучения downstream-классификатора над предобученными эмбеддингами. А можете обучать все в единой модели end-to-end.
 
Загрузка решения
Решение неободимо загружать в виде CSV-файла submission.csv следующего формата: 
id,is_bot
12,0.55
21,0.73
33,0.96
...
До закрытия соревнования командам необходимо отметить то решение, которое они считают лучшим, и именно по отмеченным решениям будет строится private-лидерборд. После того как команда отмечает итоговое решение, следующий шаг – это загрузить код который сгенерировал submission.csv. Допустимые форматы: .zip, .ipynb, .py. Ожидаем, что в приложенном коде будет понятно описана структура обучаемых моделей, а также самого процессе обучения. Напомним, это необходимо, чтобы жюри могло проверить обучения TLS-эмбеддинга. Если код отсутствует или невалиден, то такие решения рассматриваться не будут.

Важно
До конца соревнования вам обязательно надо отметить итоговое решение и прикрепить для него код. Если этого не сделать, то мы не сможем оценить ваше решение.
Прикрепляйте файл/архив для итогового решения. К сожалению, платформа устроена так, что при каждом новом сабмите кода файл будет перетираться. Поэтому когда соревнование завершится в прикрепленном файле должен быть код для выбранной посылки.
Чтобы не беспокоиться насчет соответствия вашего кода финальной попытке, советуем сохранить последнюю посылку для переотправки вашего лучшего решения, для которого необходимо: прикрепить соответствующий код, отметить данное решение финальным.
Baseline
К соревнованию мы приложили ipython-ноутбук с простым бейзлайном. Что в нем происходит:
TLS-шифры и TLS-кривые рассматриваются как единая строка текста с [SEP]-разделителем. 
На TLS-текстах из прошлого пункта обучается BPE-токенайзер.
На всей train-выборке обучается простая нейронная-сеть. TLS-эмбеддинг – это усредненный эмбеддинг каждого токена.
Перебора параметров нет.
Решение достаточно простое и поэтому выбивает не очень высокий ROCAUC – около 0.68, но с этого можно начать.
